# é…ç½®ç³»ç»Ÿæ€»è§ˆæŒ‡å—

æœ¬é¡¹ç›®é‡‡ç”¨ç»Ÿä¸€çš„é…ç½®ç®¡ç†ç³»ç»Ÿï¼Œå°†æ‰€æœ‰è®­ç»ƒå’Œç¯å¢ƒå‚æ•°é›†ä¸­ç®¡ç†ï¼Œä¾¿äºå®éªŒè¿½è¸ªå’Œå¤ç°ã€‚

## ğŸ“ é…ç½®ç³»ç»Ÿç»“æ„

```
data/
â”œâ”€â”€ ppo_configs/              # PPOè®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ training_config.py    # PPOè®­ç»ƒé…ç½®ç±»
â”‚   â”œâ”€â”€ default_config.json   # é»˜è®¤PPOé…ç½®
â”‚   â”œâ”€â”€ phase1_config.json    # é˜¶æ®µ1 PPOé…ç½®
â”‚   â”œâ”€â”€ phase2_config.json    # é˜¶æ®µ2 PPOé…ç½®
â”‚   â”œâ”€â”€ training_runs/        # è®­ç»ƒè¿è¡Œé…ç½®è®°å½•
â”‚   â”œâ”€â”€ usage_example.py      # ä½¿ç”¨ç¤ºä¾‹
â”‚   â””â”€â”€ README.md             # è¯¦ç»†è¯´æ˜
â”‚
â”œâ”€â”€ petri_configs/            # Petriç½‘ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ env_config.py         # ç¯å¢ƒé…ç½®ç±»
â”‚   â”œâ”€â”€ default_config.json   # é»˜è®¤ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ phase1_config.json    # é˜¶æ®µ1ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ phase2_config.json    # é˜¶æ®µ2ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ usage_example.py      # ä½¿ç”¨ç¤ºä¾‹
â”‚   â””â”€â”€ README.md             # è¯¦ç»†è¯´æ˜
â”‚
â””â”€â”€ CONFIG_SYSTEM_GUIDE.md    # æœ¬æ–‡æ¡£
```

## ğŸ¯ ä¸¤å¤§é…ç½®ç³»ç»Ÿ

### 1. PPOè®­ç»ƒé…ç½® (`ppo_configs/`)

ç®¡ç†PPOå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ‰€æœ‰è¶…å‚æ•°ï¼š

**ä¸»è¦å‚æ•°:**
- ç½‘ç»œç»“æ„: `n_hidden`, `n_layer`
- è®­ç»ƒæ‰¹æ¬¡: `total_batch`, `sub_batch_size`, `num_epochs`
- PPOç®—æ³•: `gamma`, `gae_lambda`, `clip_epsilon`, `lr`
- ç†µç³»æ•°: `entropy_start`, `entropy_end`
- è¡Œä¸ºå…‹éš†: `lambda_bc0`, `bc_decay_batches`

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from data.ppo_configs.training_config import PPOTrainingConfig
from solutions.PPO.train import train

# åŠ è½½é…ç½®
config = PPOTrainingConfig.load("data/ppo_configs/phase1_config.json")

# è®­ç»ƒ
log, policy = train(env, eval_env, config=config)
```

### 2. Petriç½‘ç¯å¢ƒé…ç½® (`petri_configs/`)

ç®¡ç†Petriç½‘ä»¿çœŸç¯å¢ƒçš„æ‰€æœ‰å‚æ•°ï¼š

**ä¸»è¦å‚æ•°:**
- ç¯å¢ƒå‚æ•°: `n_wafer`
- å¥–åŠ±å‚æ•°: `c_time`, `R_done`, `R_scrap`
- é¢„è­¦å‚æ•°: `T_warn`, `a_warn`, `T_safe`, `b_safe`
- è¶…æ—¶ç³»æ•°: `D_Residual_time`, `P_Residual_time`
- å¥–åŠ±å¼€å…³: `reward_config`

**ä½¿ç”¨ç¤ºä¾‹:**
```python
from data.petri_configs.env_config import PetriEnvConfig
from solutions.Continuous_model.pn import Petri

# åŠ è½½é…ç½®
config = PetriEnvConfig.load("data/petri_configs/phase1_config.json")

# åˆ›å»ºç¯å¢ƒ
net = Petri(config=config)
```

## ğŸ”„ ä¸¤é˜¶æ®µè¯¾ç¨‹å­¦ä¹ 

æœ¬é¡¹ç›®é‡‡ç”¨ä¸¤é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼š

### é˜¶æ®µ1: åŸºç¡€è®­ç»ƒï¼ˆä»…æŠ¥åºŸæƒ©ç½šï¼‰

**ç›®æ ‡**: è®©æ¨¡å‹å­¦ä¹ é¿å…åŸºæœ¬é”™è¯¯ï¼ˆåŠ å·¥è…”å®¤è¶…æ—¶ï¼‰

**é…ç½®:**
- PPO: `data/ppo_configs/phase1_config.json`
- Petri: `data/petri_configs/phase1_config.json`
- ç‰¹ç‚¹: `training_phase=1`, `transport_penalty=0`

**è¿è¡Œ:**
```bash
python solutions/PPO/run_ppo.py --phase 1
```

### é˜¶æ®µ2: é«˜çº§è®­ç»ƒï¼ˆå®Œæ•´å¥–åŠ±ï¼‰

**ç›®æ ‡**: åœ¨é˜¶æ®µ1åŸºç¡€ä¸Šï¼Œä¼˜åŒ–è¿è¾“ä½ä½¿ç”¨

**é…ç½®:**
- PPO: `data/ppo_configs/phase2_config.json`
- Petri: `data/petri_configs/phase2_config.json`
- ç‰¹ç‚¹: `training_phase=2`, `transport_penalty=1`

**è¿è¡Œ:**
```bash
python solutions/PPO/run_ppo.py --phase 2
# è‡ªåŠ¨åŠ è½½é˜¶æ®µ1çš„checkpointç»§ç»­è®­ç»ƒ
```

### è‡ªåŠ¨ä¸¤é˜¶æ®µè®­ç»ƒ

```bash
python solutions/PPO/run_ppo.py --auto-phase2
# è‡ªåŠ¨æ‰§è¡Œ Phase 1 -> Phase 2
```

## ğŸ“ é…ç½®æ–‡ä»¶ç®¡ç†æœ€ä½³å®è·µ

### 1. å®éªŒç‰ˆæœ¬æ§åˆ¶

æ¯æ¬¡è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜é…ç½®å¿«ç…§åˆ° `training_runs/`ï¼š
```
data/ppo_configs/training_runs/
â”œâ”€â”€ config_phase1_20260122_143000.json
â”œâ”€â”€ config_phase2_20260122_150000.json
â””â”€â”€ ...
```

è¿™æ ·å¯ä»¥è¿½æº¯æ¯æ¬¡å®éªŒçš„ç¡®åˆ‡é…ç½®ã€‚

### 2. åˆ›å»ºå®éªŒé…ç½®

```python
# æ–¹æ³•1: ä¿®æ”¹ç°æœ‰é…ç½®
from data.ppo_configs.training_config import PPOTrainingConfig

config = PPOTrainingConfig.load("data/ppo_configs/phase1_config.json")
config.lr = 5e-4
config.total_batch = 300
config.save("data/ppo_configs/experiment_01.json")

# æ–¹æ³•2: åˆ›å»ºæ–°é…ç½®
config = PPOTrainingConfig(
    n_hidden=256,
    total_batch=200,
    lr=1e-3,
    training_phase=1
)
config.save("data/ppo_configs/experiment_02.json")
```

### 3. è¶…å‚æ•°è°ƒä¼˜

```python
# åˆ›å»ºå‚æ•°æ‰«æé…ç½®
for lr in [1e-3, 5e-4, 1e-4]:
    for n_hidden in [64, 128, 256]:
        config = PPOTrainingConfig(
            lr=lr,
            n_hidden=n_hidden,
            training_phase=1
        )
        config.save(f"data/ppo_configs/sweep_lr{lr}_h{n_hidden}.json")
```

## ğŸ”§ å‘½ä»¤è¡Œå·¥å…·é›†æˆ

### PPOè®­ç»ƒå‘½ä»¤è¡Œå‚æ•°

```bash
# åŸºç¡€ç”¨æ³•
python solutions/PPO/run_ppo.py --phase 1

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python solutions/PPO/run_ppo.py --config data/ppo_configs/my_config.json

# GPUè®­ç»ƒ
python solutions/PPO/run_ppo.py --phase 1 --device cuda

# ä½¿ç”¨é¢„è®­ç»ƒ
python solutions/PPO/run_ppo.py --phase 1 --with-pretrain

# ä»checkpointç»§ç»­
python solutions/PPO/run_ppo.py \
    --phase 2 \
    --checkpoint solutions/PPO/saved_models/CT_phase1_latest.pt

# å®Œæ•´ç¤ºä¾‹
python solutions/PPO/run_ppo.py \
    --config data/ppo_configs/experiment_01.json \
    --device cuda \
    --with-pretrain
```

## ğŸ“Š é…ç½®å¯¹æ¯”å·¥å…·

### æ¯”è¾ƒä¸¤ä¸ªé…ç½®æ–‡ä»¶

```python
from data.ppo_configs.training_config import PPOTrainingConfig

config1 = PPOTrainingConfig.load("data/ppo_configs/phase1_config.json")
config2 = PPOTrainingConfig.load("data/ppo_configs/phase2_config.json")

# æ‰“å°é…ç½®
print(config1)
print(config2)

# æ¯”è¾ƒå·®å¼‚
import json
dict1 = config1.to_dict() if hasattr(config1, 'to_dict') else config1.__dict__
dict2 = config2.to_dict() if hasattr(config2, 'to_dict') else config2.__dict__

for key in dict1:
    if dict1[key] != dict2[key]:
        print(f"{key}: {dict1[key]} -> {dict2[key]}")
```

## ğŸ¨ è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹

### ç¤ºä¾‹1: å¿«é€Ÿè®­ç»ƒé…ç½®

```json
{
  "n_hidden": 64,
  "n_layer": 3,
  "total_batch": 50,
  "sub_batch_size": 32,
  "num_epochs": 5,
  "lr": 1e-3,
  "training_phase": 1
}
```

### ç¤ºä¾‹2: é«˜ç²¾åº¦è®­ç»ƒé…ç½®

```json
{
  "n_hidden": 256,
  "n_layer": 6,
  "total_batch": 300,
  "sub_batch_size": 128,
  "num_epochs": 20,
  "lr": 5e-5,
  "training_phase": 2
}
```

### ç¤ºä¾‹3: è‡ªå®šä¹‰å¥–åŠ±æƒé‡

```json
{
  "n_wafer": 4,
  "c_time": 1.0,
  "R_done": 200,
  "R_scrap": 150,
  "training_phase": 2,
  "reward_config": {
    "proc_reward": 1,
    "safe_reward": 0,
    "penalty": 1,
    "warn_penalty": 0,
    "transport_penalty": 1,
    "congestion_penalty": 1,
    "time_cost": 1,
    "release_violation_penalty": 1
  }
}
```

## ğŸ” é…ç½®éªŒè¯å’Œè°ƒè¯•

### éªŒè¯é…ç½®æœ‰æ•ˆæ€§

```python
from data.ppo_configs.training_config import PPOTrainingConfig
from data.petri_configs.env_config import PetriEnvConfig

# åŠ è½½å¹¶éªŒè¯PPOé…ç½®
try:
    ppo_config = PPOTrainingConfig.load("data/ppo_configs/my_config.json")
    print("âœ“ PPOé…ç½®æœ‰æ•ˆ")
    print(ppo_config)
except Exception as e:
    print(f"âœ— PPOé…ç½®é”™è¯¯: {e}")

# åŠ è½½å¹¶éªŒè¯ç¯å¢ƒé…ç½®
try:
    env_config = PetriEnvConfig.load("data/petri_configs/my_config.json")
    print("âœ“ ç¯å¢ƒé…ç½®æœ‰æ•ˆ")
    print(env_config)
except Exception as e:
    print(f"âœ— ç¯å¢ƒé…ç½®é”™è¯¯: {e}")
```

### æ£€æŸ¥é…ç½®ä¸€è‡´æ€§

```python
# ç¡®ä¿è®­ç»ƒé˜¶æ®µä¸€è‡´
ppo_config = PPOTrainingConfig.load("data/ppo_configs/phase1_config.json")
env_config = PetriEnvConfig.load("data/petri_configs/phase1_config.json")

assert ppo_config.training_phase == env_config.training_phase, \
    "PPOå’Œç¯å¢ƒçš„è®­ç»ƒé˜¶æ®µå¿…é¡»ä¸€è‡´ï¼"

print(f"âœ“ é…ç½®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡ (Phase {ppo_config.training_phase})")
```

## ğŸ“š å‚è€ƒæ–‡æ¡£

- **PPOé…ç½®è¯¦ç»†è¯´æ˜**: `data/ppo_configs/README.md`
- **Petriç¯å¢ƒé…ç½®è¯´æ˜**: `data/petri_configs/README.md`
- **PPOè¿è¡ŒæŒ‡å—**: `solutions/PPO/RUN_GUIDE.md`
- **ä½¿ç”¨ç¤ºä¾‹**:
  - `data/ppo_configs/usage_example.py`
  - `data/petri_configs/usage_example.py`

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–°æ‰‹å…¥é—¨

```bash
# 1. ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python solutions/PPO/run_ppo.py

# 2. æŸ¥çœ‹é…ç½®
cat data/ppo_configs/default_config.json
cat data/petri_configs/default_config.json

# 3. è¿è¡Œç¤ºä¾‹
python data/ppo_configs/usage_example.py
python data/petri_configs/usage_example.py
```

### é«˜çº§ç”¨æˆ·

```bash
# 1. åˆ›å»ºè‡ªå®šä¹‰é…ç½®
python -c "
from data.ppo_configs.training_config import PPOTrainingConfig
config = PPOTrainingConfig(lr=5e-4, total_batch=200)
config.save('data/ppo_configs/my_exp.json')
"

# 2. ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è®­ç»ƒ
python solutions/PPO/run_ppo.py --config data/ppo_configs/my_exp.json

# 3. è‡ªåŠ¨ä¸¤é˜¶æ®µè®­ç»ƒ
python solutions/PPO/run_ppo.py --auto-phase2 --device cuda
```

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: é…ç½®æ–‡ä»¶æ‰¾ä¸åˆ°ï¼Ÿ
**A**: ç¡®ä¿ä½¿ç”¨ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„ï¼Œä¾‹å¦‚ `data/ppo_configs/xxx.json`

### Q2: ä¿®æ”¹é…ç½®åæ²¡æœ‰ç”Ÿæ•ˆï¼Ÿ
**A**: æ£€æŸ¥æ˜¯å¦æ­£ç¡®ä¼ é€’äº†é…ç½®å¯¹è±¡/è·¯å¾„ç»™è®­ç»ƒå‡½æ•°

### Q3: å¦‚ä½•æ¢å¤ä¹‹å‰çš„è®­ç»ƒï¼Ÿ
**A**: æŸ¥çœ‹ `data/ppo_configs/training_runs/` æ‰¾åˆ°å¯¹åº”æ—¶é—´æˆ³çš„é…ç½®æ–‡ä»¶

### Q4: ä¸¤ä¸ªé…ç½®ç³»ç»Ÿå¦‚ä½•ååŒï¼Ÿ
**A**: PPOé…ç½®ç®¡ç†è®­ç»ƒè¿‡ç¨‹ï¼ŒPetrié…ç½®ç®¡ç†ç¯å¢ƒå‚æ•°ï¼Œç¡®ä¿ä¸¤è€…çš„ `training_phase` ä¸€è‡´

## ğŸ’¡ å°è´´å£«

1. **é…ç½®å‘½å**: ä½¿ç”¨æè¿°æ€§çš„æ–‡ä»¶åï¼Œå¦‚ `high_lr_large_batch.json`
2. **ç‰ˆæœ¬ç®¡ç†**: é‡è¦é…ç½®æ–‡ä»¶åŠ å…¥Gitç‰ˆæœ¬æ§åˆ¶
3. **æ³¨é‡Šè®°å½•**: åœ¨å®éªŒç¬”è®°ä¸­è®°å½•é…ç½®æ–‡ä»¶è·¯å¾„å’Œå®éªŒç»“æœ
4. **å¤‡ä»½é…ç½®**: å®šæœŸå¤‡ä»½ `training_runs/` ç›®å½•
5. **å‚æ•°æœç´¢**: ä½¿ç”¨è„šæœ¬æ‰¹é‡ç”Ÿæˆé…ç½®æ–‡ä»¶è¿›è¡Œè¶…å‚æ•°æœç´¢
